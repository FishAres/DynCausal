{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, time_series, sequence_length, prediction_step=1):\n",
    "        self.time_series = torch.FloatTensor(time_series)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_step = prediction_step\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_series) - self.sequence_length - self.prediction_step + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y = self.time_series[idx : idx + self.sequence_length]\n",
    "        y_dot = (\n",
    "            self.time_series[\n",
    "                idx\n",
    "                + self.prediction_step : idx\n",
    "                + self.sequence_length\n",
    "                + self.prediction_step\n",
    "            ]\n",
    "            - self.time_series[idx : idx + self.sequence_length]\n",
    "        ) / self.prediction_step\n",
    "        return y, y_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDyAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, library_dim):\n",
    "        super().__init__()\n",
    "        self.encoder_lstm = nn.LSTM(input_dim, 32, batch_first=True)\n",
    "        self.encoder_linear = nn.Linear(32, latent_dim)\n",
    "        self.decoder_linear = nn.Linear(latent_dim, 32)\n",
    "        self.decoder_lstm = nn.LSTM(32, input_dim, batch_first=True)\n",
    "        self.library = SINDyLibrary(latent_dim)\n",
    "        self.xi = nn.Parameter(torch.randn(library_dim, latent_dim).cuda())\n",
    "\n",
    "    def forward(self, y):\n",
    "        # y shape: [batch_size, sequence_length, input_dim]\n",
    "        lstm_out, _ = self.encoder_lstm(y)\n",
    "        z = self.encoder_linear(\n",
    "            lstm_out\n",
    "        )  # z shape: [batch_size, sequence_length, latent_dim]\n",
    "\n",
    "        decoder_in = self.decoder_linear(z)\n",
    "        y_reconstructed, _ = self.decoder_lstm(decoder_in)\n",
    "        return z, y_reconstructed\n",
    "\n",
    "    def encoder(self, y):\n",
    "        lstm_out, _ = self.encoder_lstm(y)\n",
    "        return self.encoder_linear(lstm_out)\n",
    "\n",
    "    def decoder(self, z):\n",
    "        decoder_in = self.decoder_linear(z)\n",
    "        y_reconstructed, _ = self.decoder_lstm(decoder_in)\n",
    "        return y_reconstructed\n",
    "\n",
    "    def sindy_predict(self, z):\n",
    "        # Ensure z is 3D: [batch_size, sequence_length, latent_dim]\n",
    "        if z.dim() == 2:\n",
    "            z = z.unsqueeze(1)\n",
    "        theta = self.library(z)\n",
    "        return torch.einsum(\"...ij,jk->...ik\", theta, self.xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd.functional as F\n",
    "\n",
    "\n",
    "def compute_sindy_losses(model, y, y_dot):\n",
    "    # Ensure y requires grad\n",
    "    y = y.detach().requires_grad_(True)\n",
    "\n",
    "    # Forward pass\n",
    "    z, y_reconstructed = model(y)\n",
    "\n",
    "    # Compute gradients\n",
    "    d_phi_d_y = F.jacobian(model.encoder, y)\n",
    "    d_phi_d_y = d_phi_d_y.permute(0, 2, 1, 3)\n",
    "\n",
    "    # Compute SINDy prediction\n",
    "    z_dot_sindy = model.sindy_predict(z)\n",
    "\n",
    "    # Compute L_ż\n",
    "    z_dot_chain_rule = torch.matmul(d_phi_d_y, y_dot.unsqueeze(-1)).squeeze(-1)\n",
    "    L_z_dot = torch.norm(z_dot_chain_rule - z_dot_sindy, p=2, dim=(1, 2)).mean()\n",
    "\n",
    "    # Compute L_ẏ\n",
    "    d_psi_d_z = F.jacobian(model.decoder, z)\n",
    "    d_psi_d_z = d_psi_d_z.permute(0, 2, 1, 3)\n",
    "\n",
    "    y_dot_reconstructed = torch.matmul(d_psi_d_z, z_dot_sindy.unsqueeze(-1)).squeeze(-1)\n",
    "    L_y_dot = torch.norm(y_dot - y_dot_reconstructed, p=2, dim=(1, 2)).mean()\n",
    "\n",
    "    return L_z_dot, L_y_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDyLibrary(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Ensure z is 3D: [batch_size, sequence_length, latent_dim]\n",
    "        if z.dim() == 2:\n",
    "            z = z.unsqueeze(1)\n",
    "\n",
    "        batch_size, seq_len, _ = z.shape\n",
    "        library = [torch.ones(batch_size, seq_len, 1).to(z.device)]\n",
    "        for i in range(self.latent_dim):\n",
    "            library.append(z[:, :, i : i + 1])\n",
    "            for j in range(i, self.latent_dim):\n",
    "                library.append(z[:, :, i : i + 1] * z[:, :, j : j + 1])\n",
    "        return torch.cat(library, dim=2)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model, data_loader, num_epochs, learning_rate, lambda_1, lambda_2):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Initialize tqdm progress bar\n",
    "        pbar = tqdm(total=len(data_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Initialize loss accumulators\n",
    "        epoch_recon_loss = 0\n",
    "        epoch_z_dot_loss = 0\n",
    "        epoch_y_dot_loss = 0\n",
    "        epoch_total_loss = 0\n",
    "\n",
    "        for batch in data_loader:\n",
    "            y, y_dot = batch\n",
    "            y = y.cuda()\n",
    "            y_dot = y_dot.cuda()\n",
    "\n",
    "            # Forward pass\n",
    "            z, y_reconstructed = model(y)\n",
    "\n",
    "            # Compute losses\n",
    "            reconstruction_loss = mse_loss(y, y_reconstructed)\n",
    "            L_z_dot, L_y_dot = compute_sindy_losses(model, y, y_dot)\n",
    "\n",
    "            # Total loss\n",
    "            total_loss = reconstruction_loss + lambda_1 * L_z_dot + lambda_2 * L_y_dot\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate losses\n",
    "            epoch_recon_loss += reconstruction_loss.item()\n",
    "            epoch_z_dot_loss += L_z_dot.item()\n",
    "            epoch_y_dot_loss += L_y_dot.item()\n",
    "            epoch_total_loss += total_loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(\n",
    "                {\n",
    "                    \"Recon Loss\": f\"{epoch_recon_loss / (pbar.n + 1):.4f}\",\n",
    "                    \"Z_dot Loss\": f\"{epoch_z_dot_loss / (pbar.n + 1):.4f}\",\n",
    "                    \"Y_dot Loss\": f\"{epoch_y_dot_loss / (pbar.n + 1):.4f}\",\n",
    "                    \"Total Loss\": f\"{epoch_total_loss / (pbar.n + 1):.4f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Close progress bar\n",
    "        pbar.close()\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Recon Loss: {epoch_recon_loss / len(data_loader):.4f}\")\n",
    "        print(f\"  Z_dot Loss: {epoch_z_dot_loss / len(data_loader):.4f}\")\n",
    "        print(f\"  Y_dot Loss: {epoch_y_dot_loss / len(data_loader):.4f}\")\n",
    "        print(f\"  Total Loss: {epoch_total_loss / len(data_loader):.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../data/exp_pro/v1_anim5_tp6_actwvelp.npy\", allow_pickle=True)\n",
    "x = data[100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50  # Length of input sequences\n",
    "batch_size = 32\n",
    "prediction_step = 1  # For computing y_dot\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TimeSeriesDataset(x, sequence_length, prediction_step)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "input_dim = 3  # Adjust based on your data\n",
    "latent_dim = 2  # Adjust based on your expected system complexity\n",
    "library_dim = 6  # Adjust based on your SINDy library\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "lambda_1 = 0.1  # Weight for L_z_dot\n",
    "lambda_2 = 0.1  # Weight for L_y_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_dot = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SINDyAutoencoder(50, latent_dim, library_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  20%|█▉        | 46/233 [00:51<03:32,  1.13s/it, Recon Loss=0.9601, Z_dot Loss=1.4889, Y_dot Loss=6.3128, Total Loss=1.7403]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 47\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, num_epochs, learning_rate, lambda_1, lambda_2)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n\u001b[0;32m     46\u001b[0m reconstruction_loss \u001b[38;5;241m=\u001b[39m mse_loss(y, y_reconstructed)\n\u001b[1;32m---> 47\u001b[0m L_z_dot, L_y_dot \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_sindy_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Total loss\u001b[39;00m\n\u001b[0;32m     50\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m reconstruction_loss \u001b[38;5;241m+\u001b[39m lambda_1 \u001b[38;5;241m*\u001b[39m L_z_dot \u001b[38;5;241m+\u001b[39m lambda_2 \u001b[38;5;241m*\u001b[39m L_y_dot\n",
      "Cell \u001b[1;32mIn[20], line 24\u001b[0m, in \u001b[0;36mcompute_sindy_losses\u001b[1;34m(model, y, y_dot)\u001b[0m\n\u001b[0;32m     21\u001b[0m L_z_dot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(z_dot_chain_rule \u001b[38;5;241m-\u001b[39m z_dot_sindy, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Compute L_ẏ\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m d_psi_d_z \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m d_psi_d_z \u001b[38;5;241m=\u001b[39m d_psi_d_z\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     27\u001b[0m y_dot_reconstructed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(d_psi_d_z, z_dot_sindy\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\functional.py:673\u001b[0m, in \u001b[0;36mjacobian\u001b[1;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[0;32m    671\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[1;32m--> 673\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[0;32m    677\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\functional.py:159\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:300\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, dataloader, num_epochs, learning_rate, lambda_1, lambda_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_dot = next(iter(dataloader))\n",
    "z, y_reconstructed = model(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model.library(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 6]), torch.Size([6, 2]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape, model.xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (32) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Compute L_ẏ\u001b[39;00m\n\u001b[0;32m     21\u001b[0m d_psi_d_z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mjacobian(model\u001b[38;5;241m.\u001b[39mdecoder, z)\n\u001b[1;32m---> 22\u001b[0m y_dot_reconstructed \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_psi_d_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_dot_sindy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     23\u001b[0m L_y_dot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(y_dot \u001b[38;5;241m-\u001b[39m y_dot_reconstructed, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (32) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "y, y_dot = next(iter(dataloader))\n",
    "\n",
    "y = y.detach().requires_grad_(True)\n",
    "\n",
    "z = model.encoder(y)\n",
    "y_reconstructed = model.decoder(z)\n",
    "\n",
    "# Compute gradients\n",
    "d_phi_d_y = torch.autograd.functional.jacobian(model.encoder, y)\n",
    "\n",
    "# Compute SINDy prediction\n",
    "z_dot_sindy = model.sindy_predict(z)\n",
    "\n",
    "# Compute L_ż\n",
    "# Reshape d_phi_d_y for batch matrix multiplication\n",
    "d_phi_d_y = d_phi_d_y.permute(0, 2, 1, 3)  # (batch, latent_dim, seq_len, feature_dim)\n",
    "z_dot_chain_rule = torch.matmul(d_phi_d_y, y_dot.unsqueeze(-1)).squeeze(-1)\n",
    "L_z_dot = torch.norm(z_dot_chain_rule - z_dot_sindy, p=2, dim=(1, 2)).mean()\n",
    "\n",
    "# Compute L_ẏ\n",
    "d_psi_d_z = torch.autograd.functional.jacobian(model.decoder, z)\n",
    "y_dot_reconstructed = torch.matmul(d_psi_d_z, z_dot_sindy.unsqueeze(-1)).squeeze(-1)\n",
    "L_y_dot = torch.norm(y_dot - y_dot_reconstructed, p=2, dim=(1, 2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 50, 32, 2]), torch.Size([32, 2, 1]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_psi_d_z.shape, z_dot_sindy.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sindy_losses(model, y, y_dot):\n",
    "    # Ensure y requires grad\n",
    "    y = y.detach().requires_grad_(True)\n",
    "\n",
    "    z = model.encoder(y)\n",
    "    y_reconstructed = model.decoder(z)\n",
    "\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"y_dot shape: {y_dot.shape}\")\n",
    "    print(f\"z shape: {z.shape}\")\n",
    "    print(f\"y_reconstructed shape: {y_reconstructed.shape}\")\n",
    "\n",
    "    # Compute gradients\n",
    "    d_phi_d_y = torch.autograd.functional.jacobian(model.encoder, y)\n",
    "    print(f\"d_phi_d_y shape: {d_phi_d_y.shape}\")\n",
    "\n",
    "    # Compute SINDy prediction\n",
    "    z_dot_sindy = model.sindy_predict(z)\n",
    "    print(f\"z_dot_sindy shape: {z_dot_sindy.shape}\")\n",
    "\n",
    "    # Compute L_ż\n",
    "    # Reshape d_phi_d_y for batch matrix multiplication\n",
    "    d_phi_d_y = d_phi_d_y.permute(\n",
    "        0, 2, 1, 3\n",
    "    )  # (batch, latent_dim, seq_len, feature_dim)\n",
    "    z_dot_chain_rule = torch.matmul(d_phi_d_y, y_dot.unsqueeze(-1)).squeeze(-1)\n",
    "    print(f\"z_dot_chain_rule shape: {z_dot_chain_rule.shape}\")\n",
    "    L_z_dot = torch.norm(z_dot_chain_rule - z_dot_sindy, p=2, dim=(1, 2)).mean()\n",
    "\n",
    "    # Compute L_ẏ\n",
    "    d_psi_d_z = torch.autograd.functional.jacobian(model.decoder, z)\n",
    "    print(f\"d_psi_d_z shape: {d_psi_d_z.shape}\")\n",
    "    y_dot_reconstructed = torch.matmul(d_psi_d_z, z_dot_sindy.unsqueeze(-1)).squeeze(-1)\n",
    "    L_y_dot = torch.norm(y_dot - y_dot_reconstructed, p=2, dim=(1, 2)).mean()\n",
    "\n",
    "    return L_z_dot, L_y_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y, y_dot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcompute_sindy_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dot\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[67], line 5\u001b[0m, in \u001b[0;36mcompute_sindy_losses\u001b[1;34m(model, y, y_dot)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_sindy_losses\u001b[39m(model, y, y_dot):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Ensure y requires grad\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     y_reconstructed \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[65], line 14\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\aresf\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "y, y_dot = next(iter(dataloader))\n",
    "\n",
    "compute_sindy_losses(model, y, y_dot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
